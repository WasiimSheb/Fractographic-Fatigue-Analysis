{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:25:33.436947Z",
     "start_time": "2024-07-29T18:25:27.953630Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "\n",
    "# Input directory containing the images\n",
    "input_dir =\"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\AL-13.5.25\" # change the path to the image\n",
    "# Model paths\n",
    "ext_model_path = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\models\\\\external_mask_unet_model.h5\" # change the path to the model\n",
    "int_model_path = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\models\\\\internal_smaller_mask_unet_model.h5\" # change the path to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:25:46.126228Z",
     "start_time": "2024-07-29T18:25:33.441228Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "# Iterate through the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.tif'):  # Check for TIFF images\n",
    "        image_path = os.path.join(input_dir, filename)  # Full path to image\n",
    "        im = Image.open(image_path)\n",
    "        png_path = image_path[:-3] + 'png'  # Replace .tif with .png\n",
    "        im.save(png_path)  # Save as PNG\n",
    "        print(f\"Converted: {filename} -> {os.path.basename(png_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:25:49.850923Z",
     "start_time": "2024-07-29T18:25:46.130402Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Iterate through all images in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.png'):  # Process only PNG files\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        \n",
    "        # Load the image\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        # Convert to grayscale and get dimensions\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        _, width = gray.shape\n",
    "        \n",
    "        # Crop to a square\n",
    "        img = img[0:width, 0:width]\n",
    "        \n",
    "        # Replace the image with the new cropped version\n",
    "        cv2.imwrite(image_path, img)\n",
    "        print(f\"Cropped and replaced: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:25:49.874378Z",
     "start_time": "2024-07-29T18:25:49.850923Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C3_0001.png...\n",
      "Completed processing for C3_0001.png\n",
      "Processing C3_0008.png...\n",
      "Completed processing for C3_0008.png\n",
      "Processing C4_0002.png...\n",
      "Completed processing for C4_0002.png\n",
      "Processing C5_0002.png...\n",
      "Completed processing for C5_0002.png\n",
      "Processing C8  (2).png...\n",
      "Completed processing for C8  (2).png\n",
      "Processing D5.png...\n",
      "Completed processing for D5.png\n",
      "Processing D6_0006.png...\n",
      "Completed processing for D6_0006.png\n",
      "Processing D6_0007.png...\n",
      "Completed processing for D6_0007.png\n",
      "Processing D7_0003.png...\n",
      "Completed processing for D7_0003.png\n",
      "Processing D8.png...\n",
      "Completed processing for D8.png\n"
     ]
    }
   ],
   "source": [
    "#Alumunium:\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def get_largest_contour(mask: np.ndarray, min_area: int = 10000):\n",
    "#     \"\"\"\n",
    "#     Extracts the largest contour from the given binary mask and filters out small irrelevant contours.\n",
    "#     Adjusting contour selection to be more adaptive to the shape.\n",
    "#     \"\"\"\n",
    "#     ret, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "#     contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     largest_contour = None\n",
    "#     if contours:\n",
    "#         # Filter contours based on area and shape (aspect ratio, circularity)\n",
    "#         valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "#         if valid_contours:\n",
    "#             largest_contour = max(valid_contours, key=cv2.contourArea)\n",
    "#     return largest_contour\n",
    "\n",
    "# def refine_mask(mask: np.ndarray, contour: np.ndarray):\n",
    "#     \"\"\"\n",
    "#     Refines the mask based on the largest contour, with less aggressive morphological operations.\n",
    "#     \"\"\"\n",
    "#     refined_mask = np.zeros_like(mask)\n",
    "#     if contour is not None:\n",
    "#         # Draw the largest contour, keeping all the areas inside it\n",
    "#         cv2.drawContours(refined_mask, [contour], -1, 255, thickness=-1)\n",
    "    \n",
    "#     # Less aggressive morphological operations to clean noise, keeping more of the shape\n",
    "#     kernel = np.ones((5, 5), np.uint8)\n",
    "#     refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "#     refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    \n",
    "#     return refined_mask\n",
    "\n",
    "# def extract_mask_from_array(image_array):\n",
    "#     \"\"\"\n",
    "#     Extracts the mask for the external contour from an image array using a CV-based approach.\n",
    "#     Adjusted to work with different lighting and edge conditions.\n",
    "#     \"\"\"\n",
    "#     if len(image_array.shape) == 3:\n",
    "#         image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         image = image_array\n",
    "\n",
    "#     # Enhance contrast using CLAHE\n",
    "#     clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "#     enhanced_image = clahe.apply(image)\n",
    "    \n",
    "#     # Smooth the image\n",
    "#     smoothed_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "    \n",
    "#     # Dynamically adjust edge detection thresholds\n",
    "#     median_intensity = np.median(smoothed_image)\n",
    "#     lower_threshold = int(max(0, (0.5 - 0.7) * median_intensity))  # Adjusted threshold range 0.5 or 1, 0.3-0.7\n",
    "#     upper_threshold = int(min(255, (0.5 + 0.7) * median_intensity))  # More adaptive range\n",
    "#     edges = cv2.Canny(smoothed_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "#     # Dilate edges to make them more continuous\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     dilated_edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "    \n",
    "#     # Fill gaps using morphological closing\n",
    "#     closed_edges = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "#     # Find the largest contour from the edges\n",
    "#     mask = np.zeros_like(image)\n",
    "#     contours, _ = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     if contours:\n",
    "#         largest_contour = max(contours, key=cv2.contourArea)\n",
    "#         cv2.drawContours(mask, [largest_contour], -1, 255, thickness=-1)\n",
    "    \n",
    "#     return mask\n",
    "\n",
    "# def extract_segmented_inner_shape(image, mask):\n",
    "#     \"\"\"\n",
    "#     Extracts the segmented inner shape by applying the refined mask to the original image.\n",
    "#     This time, the mask is refined with less aggressive cleaning to avoid removing important parts.\n",
    "#     \"\"\"\n",
    "#     # Refine the mask based on detected contours\n",
    "#     largest_contour = get_largest_contour(mask, min_area=15000)  # Adjust min_area for better accuracy\n",
    "#     refined_mask = refine_mask(mask, largest_contour)\n",
    "    \n",
    "#     # Apply the refined mask to the image\n",
    "#     segmented_inner = np.zeros_like(image)\n",
    "#     segmented_inner[refined_mask == 255] = image[refined_mask == 255]\n",
    "    \n",
    "#     return segmented_inner\n",
    "\n",
    "\n",
    "# # Input and output directories\n",
    "# input_dir =\"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\Al-NEW-part1\"\n",
    "# mask_output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\Al-NEW part1-masks\"\n",
    "# segmented_inner_output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\Al-NEW part1-segmented_inner_Shape\"\n",
    "# os.makedirs(mask_output_dir, exist_ok=True)\n",
    "# os.makedirs(segmented_inner_output_dir, exist_ok=True)\n",
    "\n",
    "# # Process images\n",
    "# for filename in os.listdir(input_dir):\n",
    "#     if filename.endswith('.png'):\n",
    "#         image_path = os.path.join(input_dir, filename)\n",
    "#         print(f\"Processing {filename}...\")\n",
    "\n",
    "#         img = cv2.imread(image_path)\n",
    "\n",
    "#         # Extract the mask\n",
    "#         mask = extract_mask_from_array(img)\n",
    "\n",
    "#         # Extract and save the segmented inner shape\n",
    "#         segmented_inner = extract_segmented_inner_shape(img, mask)\n",
    "#         segmented_inner_path = os.path.join(segmented_inner_output_dir, f\"{os.path.splitext(filename)[0]}_segmented_inner.png\")\n",
    "#         cv2.imwrite(segmented_inner_path, segmented_inner)\n",
    "\n",
    "#         # Save the binary mask image (just the mask)\n",
    "#         mask_path = os.path.join(mask_output_dir, f\"{os.path.splitext(filename)[0]}_mask.png\")\n",
    "#         cv2.imwrite(mask_path, mask)\n",
    "\n",
    "#         print(f\"Completed processing for {filename}\")\n",
    "\n",
    "#=========================================================================\n",
    "#Alumunium part 2\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def get_largest_contour(mask: np.ndarray, min_area: int = 10000):\n",
    "#     \"\"\"\n",
    "#     Extracts the largest contour from the given binary mask and filters out small irrelevant contours.\n",
    "#     \"\"\"\n",
    "#     ret, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "#     contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     largest_contour = None\n",
    "#     if contours:\n",
    "#         # Filter contours based on area\n",
    "#         valid_contours = [c for c in contours if cv2.contourArea(c) > min_area]\n",
    "#         if valid_contours:\n",
    "#             largest_contour = max(valid_contours, key=cv2.contourArea)\n",
    "#     return largest_contour\n",
    "\n",
    "# def refine_mask(mask: np.ndarray, contour: np.ndarray, center: tuple, radius: int):\n",
    "#     \"\"\"\n",
    "#     Refines the mask by keeping only the region inside the largest contour\n",
    "#     and applying a stricter circular constraint.\n",
    "#     \"\"\"\n",
    "#     refined_mask = np.zeros_like(mask)\n",
    "#     if contour is not None:\n",
    "#         # Draw the largest contour\n",
    "#         cv2.drawContours(refined_mask, [contour], -1, 255, thickness=-1)\n",
    "#         # Create a stricter circular mask\n",
    "#         circular_mask = np.zeros_like(mask)\n",
    "#         cv2.circle(circular_mask, center, radius, 255, thickness=-1)\n",
    "#         # Combine the two masks\n",
    "#         refined_mask = cv2.bitwise_and(refined_mask, circular_mask)\n",
    "    \n",
    "#     # Aggressive morphological operations to clean noise\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_OPEN, kernel, iterations=3)\n",
    "#     refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    \n",
    "#     return refined_mask\n",
    "\n",
    "# def extract_mask_from_array(image_array):\n",
    "#     \"\"\"\n",
    "#     Extracts the mask for the external contour from an image array using a CV-based approach.\n",
    "#     \"\"\"\n",
    "#     if len(image_array.shape) == 3:\n",
    "#         image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "#     else:\n",
    "#         image = image_array\n",
    "\n",
    "#     # Step 1: Enhance contrast using CLAHE\n",
    "#     clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "#     enhanced_image = clahe.apply(image)\n",
    "    \n",
    "#     # Step 2: Smooth the image\n",
    "#     smoothed_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "    \n",
    "#     # Step 3: Detect edges using dynamic Canny thresholds\n",
    "#     median_intensity = np.median(smoothed_image)\n",
    "#     lower_threshold = int(max(0, (0.5 - 0.4) * median_intensity))\n",
    "#     upper_threshold = int(min(255, (0.5+ 0.4) * median_intensity))\n",
    "#     edges = cv2.Canny(smoothed_image, lower_threshold, upper_threshold)\n",
    "    \n",
    "#     # Step 4: Dilate edges with a smaller kernel\n",
    "#     kernel = np.ones((2, 2), np.uint8)\n",
    "#     dilated_edges = cv2.dilate(edges, kernel, iterations=2)\n",
    "    \n",
    "#     # Step 5: Fill gaps using morphological closing\n",
    "#     closed_edges = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "#     # Step 6: Find the largest contour\n",
    "#     mask = np.zeros_like(image)\n",
    "#     contours, _ = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     if contours:\n",
    "#         largest_contour = max(contours, key=cv2.contourArea)\n",
    "#         cv2.drawContours(mask, [largest_contour], -1, 255, thickness=-1)\n",
    "    \n",
    "#     return mask\n",
    "\n",
    "\n",
    "# def extract_segmented_inner_shape(image, mask):\n",
    "#     \"\"\"\n",
    "#     Extracts the segmented inner shape by applying the refined mask to the original image.\n",
    "#     \"\"\"\n",
    "#     # Refine the mask using morphological operations\n",
    "#     kernel = np.ones((3, 3), np.uint8)\n",
    "#     refined_mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=3)\n",
    "#     refined_mask = cv2.morphologyEx(refined_mask, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    \n",
    "#     # Apply the refined mask to the image\n",
    "#     segmented_inner = np.zeros_like(image)\n",
    "#     segmented_inner[refined_mask == 255] = image[refined_mask == 255]\n",
    "    \n",
    "#     return segmented_inner\n",
    "\n",
    "\n",
    "# # # Input and output directories\n",
    "# input_dir =\"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\Al_Z27_01\"\n",
    "# mask_output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\stam_mask\"\n",
    "# segmented_inner_output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\stam_seg\"\n",
    "# os.makedirs(mask_output_dir, exist_ok=True)\n",
    "# os.makedirs(segmented_inner_output_dir, exist_ok=True)\n",
    "\n",
    "# # Process images\n",
    "# for filename in os.listdir(input_dir):\n",
    "#     if filename.endswith('.png'):\n",
    "#         image_path = os.path.join(input_dir, filename)\n",
    "#         print(f\"Processing {filename}...\")\n",
    "\n",
    "#         img = cv2.imread(image_path)\n",
    "\n",
    "#         # Extract the mask\n",
    "#         mask = extract_mask_from_array(img)\n",
    "#         largest_contour = get_largest_contour(mask, min_area=20000)  # Increased minimum area filter\n",
    "\n",
    "#         # Determine the center and radius for the circular region\n",
    "#         center = (mask.shape[1] // 2, mask.shape[0] // 2)\n",
    "#         if largest_contour is not None:\n",
    "#             _, enclosing_radius = cv2.minEnclosingCircle(largest_contour)\n",
    "#             radius = int(enclosing_radius * 0.85) # Shrink further to exclude fringe areas, 0.92 for EBM6, 0.85 for EBM9 , 0.80 for AI\n",
    "#         else:\n",
    "#             radius = min(center[0], center[1]) - 15\n",
    "\n",
    "#         # Refine the mask\n",
    "#         refined_mask = refine_mask(mask, largest_contour, center, radius)\n",
    "\n",
    "#         # Save the refined mask\n",
    "#         mask_path = os.path.join(mask_output_dir, f\"{os.path.splitext(filename)[0]}_mask.png\")\n",
    "#         cv2.imwrite(mask_path, refined_mask)\n",
    "\n",
    "#         # Extract and save the segmented inner shape\n",
    "#         segmented_inner = extract_segmented_inner_shape(img, refined_mask)\n",
    "#         segmented_inner_path = os.path.join(segmented_inner_output_dir, f\"{os.path.splitext(filename)[0]}_segmented_inner.png\")\n",
    "#         cv2.imwrite(segmented_inner_path, segmented_inner)\n",
    "\n",
    "#         print(f\"Completed processing for {filename}\")\n",
    "\n",
    "#=======================================================================================================================================================\n",
    "# for SLM and EBM6 images\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_contour(mask: np.ndarray):\n",
    "    \"\"\"\n",
    "    Extracts the largest contour from the given binary mask.\n",
    "    \"\"\"\n",
    "    ret, thresh = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        return largest_contour\n",
    "    return None\n",
    "\n",
    "def refine_mask(mask: np.ndarray, contour: np.ndarray, center: tuple, radius: int):\n",
    "    \"\"\"\n",
    "    Refines the mask by keeping only the region inside the largest contour\n",
    "    and applying a circular constraint.\n",
    "    \"\"\"\n",
    "    refined_mask = np.zeros_like(mask)\n",
    "    if contour is not None:\n",
    "        # Draw the largest contour\n",
    "        cv2.drawContours(refined_mask, [contour], -1, 255, thickness=-1)\n",
    "        # Create a circular mask to constrain the region\n",
    "        circular_mask = np.zeros_like(mask)\n",
    "        cv2.circle(circular_mask, center, radius, 255, thickness=-1)\n",
    "        # Combine the two masks\n",
    "        refined_mask = cv2.bitwise_and(refined_mask, circular_mask)\n",
    "    return refined_mask\n",
    "\n",
    "def extract_mask_from_array(image_array):\n",
    "    \"\"\"\n",
    "    Extracts the mask for the external contour from an image array using a CV-based approach.\n",
    "    \"\"\"\n",
    "    if len(image_array.shape) == 3:\n",
    "        image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        image = image_array\n",
    "\n",
    "    # Step 1: Enhance contrast using CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced_image = clahe.apply(image)\n",
    "    \n",
    "    # Step 2: Smooth the image\n",
    "    smoothed_image = cv2.GaussianBlur(enhanced_image, (5, 5), 0)\n",
    "    \n",
    "    # Step 3: Detect edges using Canny\n",
    "    edges = cv2.Canny(smoothed_image, 50, 150)\n",
    "    \n",
    "    # Step 4: Dilate edges with smaller kernel and more iterations\n",
    "    kernel = np.ones((2, 2), np.uint8)  # smaller kernel size\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1)  # increase iterations\n",
    "    \n",
    "    # Step 5: Fill gaps using morphological closing\n",
    "    closed_edges = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Step 6: Find the largest contour\n",
    "    mask = np.zeros_like(image)\n",
    "    contours, _ = cv2.findContours(closed_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if contours:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, 255, thickness=-1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def extract_segmented_inner_shape(image, mask):\n",
    "    \"\"\"\n",
    "    Extracts the segmented inner shape by applying the mask to the original image.\n",
    "    \"\"\"\n",
    "    # Perform morphological operations to further refine the mask\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    refined_mask = cv2.erode(mask, kernel, iterations=1)  # Increased erosion to remove more unwanted areas\n",
    "    refined_mask = cv2.dilate(refined_mask, kernel, iterations=3)  # Dilation to strengthen the relevant area\n",
    "    \n",
    "    # Apply the refined mask to the image\n",
    "    segmented_inner = np.zeros_like(image)\n",
    "    segmented_inner[refined_mask == 255] = image[refined_mask == 255]\n",
    "    \n",
    "    # Optional: Apply Gaussian blur to smooth the boundaries of the segmented region\n",
    "    segmented_inner = cv2.GaussianBlur(segmented_inner, (5, 5), 0)\n",
    "    \n",
    "    return segmented_inner\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\AL-13.5.25\"\n",
    "mask_output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\AL-13.5.25-masks\"\n",
    "segmented_inner_output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\AL-13.5.25-segmented_inner_Shape\"\n",
    "os.makedirs(mask_output_dir, exist_ok=True)\n",
    "os.makedirs(segmented_inner_output_dir, exist_ok=True)\n",
    "\n",
    "# Process images\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.png'):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        print(f\"Processing {filename}...\")\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        # Extract the mask\n",
    "        mask = extract_mask_from_array(img)\n",
    "        largest_contour = get_contour(mask)\n",
    "\n",
    "        # Determine the center and radius for the circular region\n",
    "        center = (mask.shape[1] // 2, mask.shape[0] // 2)\n",
    "        radius = min(center[0], center[1]) - 10  # Adjust the radius to fit your needs\n",
    "\n",
    "        # Refine the mask\n",
    "        refined_mask = refine_mask(mask, largest_contour, center, radius)\n",
    "\n",
    "        # Save the refined mask\n",
    "        mask_path = os.path.join(mask_output_dir, f\"{os.path.splitext(filename)[0]}_mask.png\")\n",
    "        cv2.imwrite(mask_path, refined_mask)\n",
    "\n",
    "        # Extract and save the segmented inner shape\n",
    "        segmented_inner = extract_segmented_inner_shape(img, refined_mask)\n",
    "        segmented_inner_path = os.path.join(segmented_inner_output_dir, f\"{os.path.splitext(filename)[0]}_segmented_inner.png\")\n",
    "        cv2.imwrite(segmented_inner_path, segmented_inner)\n",
    "\n",
    "        print(f\"Completed processing for {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:25:49.906459Z",
     "start_time": "2024-07-29T18:25:49.881645Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_heatmap(img, contour):\n",
    "    img_grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a mask with the contour\n",
    "    mask = np.zeros(img_grey.shape, np.uint8)\n",
    "    cv2.drawContours(mask, [contour], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    # Create an output image where the mask is applied\n",
    "    out = np.zeros_like(img)\n",
    "    out[mask == 255] = img[mask == 255]\n",
    "    img_color = cv2.cvtColor(out, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process for heatmap generation\n",
    "    img_grey = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(img_grey, (13, 13), 0)\n",
    "    \n",
    "    sobelx = cv2.Sobel(blur, cv2.CV_8U, 1, 0, ksize=5)\n",
    "    sobely = cv2.Sobel(blur, cv2.CV_8U, 0, 1, ksize=5)\n",
    "    \n",
    "    sobel_magnitude = np.sqrt(sobelx**2 + sobely**2)\n",
    "    sobel_magnitude = sobel_magnitude / sobel_magnitude.max() * 255\n",
    "    sobel_magnitude = np.uint8(sobel_magnitude)\n",
    "    \n",
    "    # Define window parameters for localized averaging\n",
    "    window_size = 201\n",
    "    window_step = 10\n",
    "    \n",
    "    heat_map_sobel = np.zeros(sobel_magnitude.shape, dtype=np.uint8)\n",
    "    \n",
    "    # Pad the images\n",
    "    sobel_c = np.pad(sobel_magnitude, int((window_size-1)/2), mode='constant', constant_values=0)\n",
    "    mask_metal_c = np.pad(mask, int((window_size-1)/2), mode='constant', constant_values=0)\n",
    "    \n",
    "    for y in range(0, sobel_c.shape[0], window_step):\n",
    "        for x in range(0, sobel_c.shape[1], window_step):\n",
    "            window = sobel_c[y:y+window_size, x:x+window_size]\n",
    "            mask_metal_window = mask_metal_c[y:y+window_size, x:x+window_size] / 255\n",
    "            if mask_metal_window.sum() == 0 or mask_metal_window[int((window_size - 1) / 2), int((window_size - 1) / 2)] == 0:\n",
    "                heat_map_sobel[y:y+window_step, x:x+window_step] = 0\n",
    "            else:\n",
    "                heat_map_sobel[y:y+window_step, x:x+window_step] = np.sum(window) / mask_metal_window.sum()\n",
    "    \n",
    "    heat_map_sobel = cv2.equalizeHist(heat_map_sobel)\n",
    "    heat_map_color_sobel = cv2.applyColorMap(heat_map_sobel, cv2.COLORMAP_JET)\n",
    "    \n",
    "    # Replace background color (set areas outside the mask to a specific color)\n",
    "    background_color = (0, 0, 0)  # Black (can be adjusted to any color)\n",
    "    heat_map_color_sobel[mask == 0] = background_color  # Set the background color\n",
    "    \n",
    "    return heat_map_color_sobel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:25:49.921987Z",
     "start_time": "2024-07-29T18:25:49.911769Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A4_05_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A4_05.tif05_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A4_06_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A4_06.tif06_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A5_05_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A5_06_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A7_05_heatmap.png\n",
      "Heatmap saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-heatmaps\\A8_05_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "def process_heatmaps(input_dir, mask_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Processes all images in a directory to generate heatmaps based on Sobel filtering.\n",
    "\n",
    "    Args:\n",
    "        input_dir (str): Directory containing input images.\n",
    "        mask_dir (str): Directory containing saved masks.\n",
    "        output_dir (str): Directory to save generated heatmaps.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.png'):  # Process only PNG files\n",
    "            image_path = os.path.join(input_dir, filename)\n",
    "            mask_path = os.path.join(mask_dir, f\"{os.path.splitext(filename)[0]}_mask.png\")\n",
    "\n",
    "            # Ensure mask exists\n",
    "            if not os.path.exists(mask_path):\n",
    "                print(f\"Mask not found for {filename}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Load the image and mask\n",
    "            img = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Get the contour from the saved mask\n",
    "            ext_contour = get_contour(mask)\n",
    "\n",
    "            if ext_contour is None:\n",
    "                print(f\"No valid contour found for {filename}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Generate the heatmap\n",
    "            heatmap_img = get_heatmap(img, ext_contour)\n",
    "\n",
    "            # Save the heatmap\n",
    "            heatmap_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_heatmap.png\")\n",
    "            cv2.imwrite(heatmap_path, heatmap_img)\n",
    "            print(f\"Heatmap saved: {heatmap_path}\")\n",
    "\n",
    "# Specify input and output directories\n",
    "input_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples\"\n",
    "mask_dir =  \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples-masks\"\n",
    "output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples-heatmaps\"\n",
    "\n",
    "# Process all images to generate heatmaps\n",
    "process_heatmaps(input_dir, mask_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-29T18:26:28.584536Z",
     "start_time": "2024-07-29T18:26:24.170207Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A4_05_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A4_05.tif05_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A4_06_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A4_06.tif06_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A5_05_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A5_06_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A7_05_combined.png\n",
      "Combined image saved: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples-Results\\A8_05_combined.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def combine_images_with_labels(original, segmented_inner, mask, heatmap, filename, output_path):\n",
    "    \"\"\"\n",
    "    Combines four images (original, segmented inner shape, mask, heatmap) into one image with the filename at the top in red.\n",
    "    Additionally, it adds labels below each image (Original Image, Segmented Inner Shape, Mask, Heatmap).\n",
    "\n",
    "    Args:\n",
    "        original (ndarray): Original image.\n",
    "        segmented_inner (ndarray): Segmented inner shape image.\n",
    "        mask (ndarray): Mask image.\n",
    "        heatmap (ndarray): Heatmap image.\n",
    "        filename (str): Filename of the original image (used as a label).\n",
    "        output_path (str): Path to save the combined image.\n",
    "    \"\"\"\n",
    "    # Resize all images to the same dimensions\n",
    "    target_size = (512, 512)  # Adjust size as needed\n",
    "    original = cv2.resize(original, target_size)\n",
    "    segmented_inner = cv2.resize(segmented_inner, target_size)\n",
    "    mask = cv2.resize(mask, target_size)\n",
    "    heatmap = cv2.resize(heatmap, target_size)\n",
    "\n",
    "    # Convert grayscale images to BGR for consistent visualization\n",
    "    if len(segmented_inner.shape) == 2:\n",
    "        segmented_inner = cv2.cvtColor(segmented_inner, cv2.COLOR_GRAY2BGR)\n",
    "    if len(mask.shape) == 2:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a black image for the filename label\n",
    "    label_height = 50\n",
    "    label_image = np.zeros((label_height, target_size[0], 3), dtype=np.uint8)\n",
    "\n",
    "    # Add the filename to the black image (filename in red)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    thickness = 2\n",
    "    red_color = (0, 0, 255)  # Red text (BGR format)\n",
    "\n",
    "    def add_label(text, color):\n",
    "        label = label_image.copy()\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, thickness)[0]\n",
    "        text_x = (label.shape[1] - text_size[0]) // 2\n",
    "        text_y = (label.shape[0] + text_size[1]) // 2\n",
    "        cv2.putText(label, text, (text_x, text_y), font, font_scale, color, thickness, cv2.LINE_AA)\n",
    "        return label\n",
    "\n",
    "    # Filename label with red text\n",
    "    filename_label = add_label(f\"{os.path.splitext(filename)[0]}\", red_color)\n",
    "\n",
    "    # Resize the filename label to match the width of the combined image (1024)\n",
    "    filename_label_resized = cv2.resize(filename_label, (original.shape[1] * 2, label_height))\n",
    "\n",
    "    # Create labels for the images (e.g., \"Original Image\", \"Segmented Inner Shape\", etc.) in white color\n",
    "    white_color = (255, 255, 255)  # White text for other labels\n",
    "    original_label = add_label(\"Original Image\", white_color)\n",
    "    segmented_inner_label = add_label(\"Segmented Inner Shape\", white_color)\n",
    "    mask_label = add_label(\"Mask\", white_color)\n",
    "    heatmap_label = add_label(\"Heatmap\", white_color)\n",
    "\n",
    "    # Combine labels and images\n",
    "    original_combined = np.vstack([original_label, original])\n",
    "    segmented_inner_combined = np.vstack([segmented_inner_label, segmented_inner])\n",
    "    mask_combined = np.vstack([mask_label, mask])\n",
    "    heatmap_combined = np.vstack([heatmap_label, heatmap])\n",
    "\n",
    "    # Stack images in a 2x2 grid\n",
    "    top_row = np.hstack([original_combined, segmented_inner_combined])\n",
    "    bottom_row = np.hstack([mask_combined, heatmap_combined])\n",
    "    combined = np.vstack([top_row, bottom_row])\n",
    "\n",
    "    # Add the filename label at the top of the final combined image\n",
    "    combined_with_filename = np.vstack([filename_label_resized, combined])\n",
    "\n",
    "    # Save the combined image\n",
    "    cv2.imwrite(output_path, combined_with_filename)\n",
    "    print(f\"Combined image saved: {output_path}\")\n",
    "\n",
    "# Directory paths\n",
    "input_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples\"\n",
    "segmented_inner_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples-segmented_inner_shape\"\n",
    "mask_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples-masks\"\n",
    "heatmap_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples-heatmaps\"\n",
    "output_dir = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\\\New Samples-Results\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.endswith('.png'):  # Process only PNG files\n",
    "        original_path = os.path.join(input_dir, filename)\n",
    "        segmented_inner_path = os.path.join(segmented_inner_dir, f\"{os.path.splitext(filename)[0]}_segmented_inner.png\")\n",
    "        mask_path = os.path.join(mask_dir, f\"{os.path.splitext(filename)[0]}_mask.png\")\n",
    "        heatmap_path = os.path.join(heatmap_dir, f\"{os.path.splitext(filename)[0]}_heatmap.png\")\n",
    "\n",
    "        # Check if all required files exist\n",
    "        if not (os.path.exists(original_path) and os.path.exists(segmented_inner_path) and \n",
    "                os.path.exists(mask_path) and os.path.exists(heatmap_path)):\n",
    "            print(f\"Missing files for {filename}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Load images\n",
    "        original = cv2.imread(original_path)\n",
    "        segmented_inner = cv2.imread(segmented_inner_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        heatmap = cv2.imread(heatmap_path)\n",
    "\n",
    "        # Combine images and save the result\n",
    "        output_path = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_combined.png\")\n",
    "        combine_images_with_labels(original, segmented_inner, mask, heatmap, filename, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Saved highlighted crack zone for A4_05.tif05_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A4_05_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A4_06.tif06_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A4_06_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A5_05_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A5_06_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A7_05_heatmap.png\n",
      "‚úî Saved highlighted crack zone for A8_05_heatmap.png\n",
      "‚úÖ Done: Highlighted crack zones saved for all heatmaps.\n"
     ]
    }
   ],
   "source": [
    " #Step: Detect Crack Zone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Directory Configuration ===\n",
    "base_path = \"C:\\\\Users\\\\shifa\\\\final project\\\\Enternal_Contours\"\n",
    "heatmap_folder = os.path.join(base_path, \"New Samples-HM\")\n",
    "highlighted_output_folder = os.path.join(base_path, \"New Samples-CrackZones\")\n",
    "os.makedirs(highlighted_output_folder, exist_ok=True)\n",
    "\n",
    "# === HSV Color Ranges ===\n",
    "color_ranges = {\n",
    "    \"dark_red\": [([0, 200, 100], [10, 255, 180]), ([160, 200, 100], [180, 255, 180])],\n",
    "    \"red\": [([0, 180, 180], [10, 255, 255]), ([160, 180, 180], [180, 255, 255])],\n",
    "    \"orange\": [([10, 100, 100], [25, 255, 255])]\n",
    "}\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "# === Process Heatmaps ===\n",
    "for filename in os.listdir(heatmap_folder):\n",
    "    if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        continue\n",
    "\n",
    "    filepath = os.path.join(heatmap_folder, filename)\n",
    "    image = cv2.imread(filepath)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Build red mask\n",
    "    red_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "    for lower, upper in color_ranges[\"dark_red\"] + color_ranges[\"red\"]:\n",
    "        red_mask |= cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)\n",
    "    red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Build orange mask\n",
    "    orange_mask = np.zeros(hsv.shape[:2], dtype=np.uint8)\n",
    "    for lower, upper in color_ranges[\"orange\"]:\n",
    "        orange_mask |= cv2.inRange(hsv, np.array(lower), np.array(upper))\n",
    "    orange_mask = cv2.morphologyEx(orange_mask, cv2.MORPH_OPEN, kernel)\n",
    "    orange_mask = cv2.morphologyEx(orange_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours\n",
    "    contours_red, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_orange, _ = cv2.findContours(orange_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    largest_contour = None\n",
    "    max_area = 0\n",
    "\n",
    "    for o in contours_orange:\n",
    "        if cv2.contourArea(o) < 50:\n",
    "            continue\n",
    "\n",
    "        M = cv2.moments(o)\n",
    "        if M[\"m00\"] == 0:\n",
    "            continue\n",
    "        cx = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cy = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "        for r in contours_red:\n",
    "            if cv2.pointPolygonTest(r, (cx, cy), False) >= 0:\n",
    "                area = cv2.contourArea(o)\n",
    "                if area > max_area:\n",
    "                    max_area = area\n",
    "                    largest_contour = o\n",
    "                break\n",
    "\n",
    "    # === Save Highlighted Heatmap\n",
    "    if largest_contour is not None:\n",
    "        overlay = image.copy()\n",
    "        (x, y), radius = cv2.minEnclosingCircle(largest_contour)\n",
    "        center = (int(x), int(y))\n",
    "        radius = int(radius)\n",
    "\n",
    "        # Draw circles in bold pink\n",
    "        cv2.circle(overlay, center, radius + 6, (255, 0, 255), 4)  # outer pink circle\n",
    "        cv2.circle(overlay, center, radius, (255, 0, 255), 6)      # inner pink circle\n",
    "\n",
    "        # Label with pink\n",
    "        text = \"Internal Orange Zone\"\n",
    "        text_position = (center[0] - radius, center[1] - radius - 10)\n",
    "        cv2.putText(overlay, text, text_position, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 6)\n",
    "\n",
    "\n",
    "        # Blend overlay\n",
    "        final_result = cv2.addWeighted(overlay, 0.75, image, 0.25, 0)\n",
    "\n",
    "        # Save only the highlighted heatmap\n",
    "        output_path = os.path.join(highlighted_output_folder, f\"{os.path.splitext(filename)[0]}_highlighted.png\")\n",
    "        cv2.imwrite(output_path, final_result)\n",
    "\n",
    "        print(f\"‚úî Saved highlighted crack zone for {filename}\")\n",
    "\n",
    "print(\"‚úÖ Done: Highlighted crack zones saved for all heatmaps.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# Step: Detect Crack Zone Using Convex Hull (for some images)\n",
    "# ---------------------------------------------------\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "#in this code we find the crack zone using convex hull \n",
    "\n",
    "# === Paths ===\n",
    "base_path = \"C:\\\\Users\\\\shifa\\\\final project\\\\Enternal_Contours\"\n",
    "input_folder = os.path.join(base_path, \"New Samples-HM\")\n",
    "output_folder = os.path.join(base_path, \"output\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# === Process each .png heatmap ===\n",
    "for image_name in os.listdir(input_folder):\n",
    "    if not image_name.lower().endswith(\".png\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(input_folder, image_name)\n",
    "    output_path = os.path.join(output_folder, image_name.replace(\"_heatmap\", \"_heatmap_highlighted\"))\n",
    "\n",
    "    # Load image and convert to HSV\n",
    "    img = cv2.imread(input_path)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # === Extended Warm HSV range (red to yellow) ===\n",
    "    lower_red1 = np.array([0, 70, 50])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([160, 70, 50])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    lower_orange = np.array([11, 70, 50])\n",
    "    upper_orange = np.array([35, 255, 255])\n",
    "\n",
    "    # Create warm zone masks\n",
    "    mask_red = cv2.bitwise_or(\n",
    "        cv2.inRange(hsv, lower_red1, upper_red1),\n",
    "        cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    )\n",
    "    mask_orange = cv2.inRange(hsv, lower_orange, upper_orange)\n",
    "    heat_mask = cv2.bitwise_or(mask_red, mask_orange)\n",
    "\n",
    "    # === Morphological smoothing ===\n",
    "    kernel = np.ones((9, 9), np.uint8)\n",
    "    heat_mask = cv2.morphologyEx(heat_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    heat_mask = cv2.morphologyEx(heat_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # === Find and draw largest contour ===\n",
    "    contours, _ = cv2.findContours(heat_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    if contours:\n",
    "        largest = max(contours, key=cv2.contourArea)\n",
    "        contour_points = largest.reshape(-1, 2)\n",
    "\n",
    "        # Apply Convex Hull\n",
    "        hull = ConvexHull(contour_points)\n",
    "        hull_points = contour_points[hull.vertices]\n",
    "\n",
    "        # Draw convex hull in bold pink\n",
    "        pink_color = (255, 0, 255)  # BGR format\n",
    "        cv2.polylines(img, [hull_points], isClosed=True, color=pink_color, thickness=10)\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ö† No contours found in: {image_name}\")\n",
    "\n",
    "    # Save the final result\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"‚úî Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A4_05.tif05.png\n",
      "‚úÖ Saved combined image for A4_05.tif05.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A4_05.png\n",
      "‚úÖ Saved combined image for A4_05.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A4_06.tif06.png\n",
      "‚úÖ Saved combined image for A4_06.tif06.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A4_06.png\n",
      "‚úÖ Saved combined image for A4_06.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A5_05.png\n",
      "‚úÖ Saved combined image for A5_05.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A5_06.png\n",
      "‚úÖ Saved combined image for A5_06.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A7_05.png\n",
      "‚úÖ Saved combined image for A7_05.png\n",
      "üîç Looking for original: C:\\Users\\shifa\\final project\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\\New Samples\\A8_05.png\n",
      "‚úÖ Saved combined image for A8_05.png\n",
      "üéâ Done combining available images!\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------\n",
    "# Step: Combine Available Original, Heatmap, and Crack Zone Highlight WITH Sample Name on Top\n",
    "# ---------------------------------------------------\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# === Directory Configuration ===\n",
    "base_path = \"C:\\\\Users\\\\shifa\\\\final project\\\\Final_Project_Fractographic_Failure_Analysis_with_CV_in_AM-main\"\n",
    "\n",
    "original_folder = os.path.join(base_path, \"New Samples\")  # Original images\n",
    "heatmap_folder = os.path.join(base_path, \"New Samples-heatmaps\")  # Heatmaps\n",
    "crackzone_folder = os.path.join(base_path, \"New Samples-CrackZone\")  # Crackzone highlights\n",
    "\n",
    "combined_output_folder = os.path.join(base_path, \"New Samples_CrackZone_Results\")\n",
    "os.makedirs(combined_output_folder, exist_ok=True)\n",
    "\n",
    "# === Text Parameters ===\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 1.2\n",
    "thickness = 2\n",
    "text_color = (0, 0, 0)  # Black text\n",
    "\n",
    "# === Process Each Image in Heatmap Folder ===\n",
    "for filename in os.listdir(heatmap_folder):\n",
    "    if not filename.lower().endswith('.png'):\n",
    "        continue\n",
    "\n",
    "    # Handle base name carefully: just remove '_heatmap' and nothing else\n",
    "    name_base = filename.replace('_heatmap', '')  # Keep (1) if it exists\n",
    "\n",
    "    # Build paths\n",
    "    original_path = os.path.join(original_folder, name_base)\n",
    "    heatmap_path = os.path.join(heatmap_folder, filename)\n",
    "    crackzone_path = os.path.join(crackzone_folder, filename.replace('_heatmap', '_heatmap_highlighted'))\n",
    "\n",
    "    images = []\n",
    "    titles = []\n",
    "\n",
    "    # Try loading original image\n",
    "    print(f\"üîç Looking for original: {original_path}\")  # DEBUG\n",
    "    if os.path.exists(original_path):\n",
    "        original_img = cv2.imread(original_path)\n",
    "        original_img = cv2.resize(original_img, (512, 512))\n",
    "        images.append(original_img)\n",
    "        titles.append(\"Original Image\")\n",
    "    else:\n",
    "        print(f\"‚ö† Original NOT found: {original_path}\")\n",
    "\n",
    "    # Try loading heatmap\n",
    "    if os.path.exists(heatmap_path):\n",
    "        heatmap_img = cv2.imread(heatmap_path)\n",
    "        heatmap_img = cv2.resize(heatmap_img, (512, 512))\n",
    "        images.append(heatmap_img)\n",
    "        titles.append(\"Heatmap\")\n",
    "    else:\n",
    "        print(f\"‚ö† Heatmap NOT found: {heatmap_path}\")\n",
    "\n",
    "    # Try loading crackzone\n",
    "    if os.path.exists(crackzone_path):\n",
    "        crackzone_img = cv2.imread(crackzone_path)\n",
    "        crackzone_img = cv2.resize(crackzone_img, (512, 512))\n",
    "        images.append(crackzone_img)\n",
    "        titles.append(\"Heatmap + Crack Zone\")\n",
    "    else:\n",
    "        print(f\"‚ö† Crackzone NOT found: {crackzone_path}\")\n",
    "\n",
    "    # If we have at least 1 image, combine and save\n",
    "    if images:\n",
    "        # Add titles above each image\n",
    "        combined_images = []\n",
    "        for img, title in zip(images, titles):\n",
    "            title_bar = np.ones((50, img.shape[1], 3), dtype=np.uint8) * 255  # White bar\n",
    "            cv2.putText(title_bar, title, (30, 35), font, font_scale, text_color, thickness, cv2.LINE_AA)\n",
    "            full_img = np.vstack((title_bar, img))\n",
    "            combined_images.append(full_img)\n",
    "\n",
    "        # Concatenate horizontally\n",
    "        combined_horizontal = np.hstack(combined_images)\n",
    "\n",
    "        # === Add full sample name at the very top ===\n",
    "        total_width = combined_horizontal.shape[1]\n",
    "        sample_title_bar = np.ones((80, total_width, 3), dtype=np.uint8) * 255  # Bigger white bar for sample name\n",
    "        clean_name = name_base.replace(\".png\", \"\")\n",
    "        cv2.putText(sample_title_bar, f\"Sample: {clean_name}\", (30, 60), font, 1.5, text_color, 3, cv2.LINE_AA)\n",
    "\n",
    "        final_combined = np.vstack((sample_title_bar, combined_horizontal))\n",
    "\n",
    "        # Save\n",
    "        save_name = name_base.replace(\".png\", \"_combined.png\")  # Clean final save name\n",
    "        output_path = os.path.join(combined_output_folder, save_name)\n",
    "        cv2.imwrite(output_path, final_combined)\n",
    "        print(f\"‚úÖ Saved combined image for {name_base}\")\n",
    "    else:\n",
    "        print(f\"‚ö† No images found for {name_base}, completely skipped.\")\n",
    "\n",
    "print(\"üéâ Done combining available images!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
